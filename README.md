å¥½çš„ï¼ä¸‹é¢æ˜¯ä½ çŽ°æœ‰ `README.md` åŠ ä¸Šå¯¹æ–°ç­–ç•¥æ”¯æŒçš„å®Œæ•´ä¿®æ”¹ç‰ˆæœ¬ï¼Œ**å·²åˆå¹¶åŽŸæœ‰å†…å®¹å¹¶è¡¥å……äº†æ–°ç‰¹æ€§è¯´æ˜Žå’Œä½¿ç”¨æ–¹æ³•**ã€‚

---

```markdown
# ðŸŽ¯ Multi-Objective Bayesian Optimization (MOBO)

A modular Python library for **multi-objective Bayesian optimization** using **Gaussian Processes (GP)** and **BoTorch**, with optional support for **adaptive noise modeling**.

> Built with [PyTorch](https://pytorch.org/), [GPyTorch](https://gpytorch.ai/), and [BoTorch](https://botorch.org/)

---

## ðŸ“¦ Features

- âœ”ï¸ Multi-objective optimization with EHVI / ALT-EI / QEHVI / PAREGO / NPAREGO / UCB
- âœ”ï¸ Strategy selection via `strategy=` argument
- âœ”ï¸ Independent GP models per objective
- âœ”ï¸ Adaptive noise learning using a neural `NoiseNet`
- âœ”ï¸ Pareto front extraction and visualization
- âœ”ï¸ Hypervolume logging per step
- âœ”ï¸ Easy-to-extend architecture for experiments

---

## ðŸ†• What's New

- âœ… **Added support for more acquisition strategies**:
  - `EHVI` â€“ Expected Hypervolume Improvement
  - `QEHVI` â€“ Batch Expected Hypervolume Improvement
  - `ALT_EI` â€“ Alternating Expected Improvement
  - `PAREGO` â€“ Scalarization-based using Chebyshev method
  - `NPAREGO` â€“ q-Expected Improvement with scalarization
  - `UCB` â€“ Upper Confidence Bound with scalarization
  - `RANDOM` â€“ Random uniform sampling baseline
- âœ… Strategy controlled via `strategy=` in `MultiObjectiveBO`
- âœ… Modular acquisition function registration using `STRATEGY_MAP`

---

## ðŸ“ Project Structure

```

mo\_bayes\_opt/
â”œâ”€â”€ models/         # GPModel, NoiseNet, GPTrainer
â”œâ”€â”€ acquisition/    # Acquisition function optimization (strategies registered here)
â”œâ”€â”€ core/           # BO loop & objective functions
â”œâ”€â”€ utils/          # Logging, visualization
â”œâ”€â”€ experiments/    # Example experiments
â”œâ”€â”€ data/           # Hypervolume log storage

````

---

## ðŸš€ Quick Start

### 1. Install Dependencies

```bash
pip install -r requirements.txt
````

### 2. Run Example Optimization

```python
def joint_objective(x):
    x1 = x[:, 0]
    x2 = x[:, 1]
    interaction = torch.sin(5 * torch.pi * x1 * x2)
    f1 = ((x[:, :3] * torch.sin(3 * torch.pi * x[:, :3])).sum(dim=-1) + 0.5 * interaction)
    f2 = (((1 - x[:, 3:]) * torch.cos(3 * torch.pi * x[:, 3:])).sum(dim=-1) - 0.3 * interaction)
    return torch.stack([f1, f2], dim=-1)

bo = MultiObjectiveBO(
    objective_fn=joint_objective,
    input_dim=3,
    bounds=torch.tensor([[0.0] * 3, [1.0] * 3]),
    ref_point=torch.tensor([0.0, 0.0]),
    strategy="PAREGO",  # ðŸ‘ˆ Choose any supported strategy here
    use_adaptive_noise=False
)
hypervolumes = bo.run(num_repeats=1, num_queries=100)
```

### 3. Output

* ðŸ“Š Console: Logs optimization progress and hypervolume
* ðŸ“ File: `data/hypervolume_log.csv` containing hypervolume progression

---

## âš™ï¸ Supported Strategies

| Strategy  | Description                                |
| --------- | ------------------------------------------ |
| `EHVI`    | Expected Hypervolume Improvement           |
| `QEHVI`   | Batch EHVI (q > 1)                         |
| `ALT_EI`  | Alternating EI over each objective         |
| `PAREGO`  | Scalarized EI with Chebyshev scalarization |
| `NPAREGO` | q-EI with scalarization                    |
| `UCB`     | Scalarized Upper Confidence Bound          |
| `RANDOM`  | Random uniform sampling                    |

---

## ðŸ§© Adding Your Own Strategy

To add a custom acquisition strategy:

1. Define your function in `acquisition/`:

```python
def get_acq_func_MY_STRATEGY(...):
    # return your acquisition function
```

2. Register it in `STRATEGY_MAP`:

```python
STRATEGY_MAP = {
    ...
    "MY_STRATEGY": get_acq_func_MY_STRATEGY,
}
```

3. Use it like:

```python
bo = MultiObjectiveBO(
    ...,
    strategy="MY_STRATEGY",
)
```

---

## ðŸ“ˆ Visualization

To visualize the Pareto front at a given step:

```python
plot_pareto(train_y, trial, step)
```

---

## ðŸ§ª Experiments

Example scripts are in `experiments/`. You can run batch or scalarized optimization, compare strategies, and log results.

---

## ðŸ“¬ Contact

If you encounter bugs or have suggestions, feel free to open an issue or contribute!

---

````
